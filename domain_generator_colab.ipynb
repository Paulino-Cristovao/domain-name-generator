{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "domain-generator-title"
      },
      "source": [
        "# ğŸš€ Domain Name Generator - Google Colab Edition\n",
        "\n",
        "This notebook provides the same functionality as the CLI version, optimized for Google Colab.\n",
        "\n",
        "## Features:\n",
        "- Train and use AI models for domain name generation\n",
        "- Support for multiple models (Llama 3.2, Phi-3, GPT-2 variants)\n",
        "- Generate domain suggestions with confidence scores\n",
        "- Comprehensive evaluation framework\n",
        "- Memory-optimized for Colab environments\n",
        "\n",
        "## Quick Start:\n",
        "1. Run the setup cells to install dependencies\n",
        "2. Choose a model configuration\n",
        "3. Train the model or load a pre-trained one\n",
        "4. Generate domain suggestions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## ğŸ“¦ Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install-dependencies",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c08a20b-7ca8-4acf-bb4e-c0f6b4ddc6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting detoxify\n",
            "  Downloading detoxify-0.5.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting better-profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from detoxify) (4.54.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from detoxify) (2.6.0+cu124)\n",
            "Requirement already satisfied: sentencepiece>=0.1.94 in /usr/local/lib/python3.11/dist-packages (from detoxify) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->detoxify) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->detoxify) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->detoxify) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->detoxify) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->detoxify) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->detoxify) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->detoxify) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->detoxify) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->detoxify) (2025.7.14)\n",
            "Downloading detoxify-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, better-profanity, detoxify\n",
            "Successfully installed better-profanity-0.7.0 detoxify-0.5.2 python-dotenv-1.1.1\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "ğŸ“¥ Downloading project files...\n",
            "âš ï¸  Please upload the project files or clone from your repository\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch transformers peft accelerate datasets tokenizers\n",
        "!pip install openai scikit-learn pandas numpy tqdm matplotlib seaborn\n",
        "!pip install detoxify better-profanity pyyaml python-dotenv\n",
        "!pip install wandb tensorboard plotly psutil\n",
        "\n",
        "# Download the project files\n",
        "import os\n",
        "if not os.path.exists('domain_generator'):\n",
        "    print(\"ğŸ“¥ Downloading project files...\")\n",
        "    # Note: In a real scenario, you'd clone from GitHub or upload files\n",
        "    print(\"âš ï¸  Please upload the project files or clone from your repository\")\n",
        "else:\n",
        "    print(\"âœ… Project files found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "setup-environment",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfd5bd7-282f-4eab-b58a-c8890af22d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ–¥ï¸  Using device: cuda\n",
            "   GPU: Tesla T4\n",
            "   Memory: 15.8 GB\n",
            "âœ… Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Setup environment and imports\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "from typing import List, Dict, Optional, Union\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Check GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ğŸ–¥ï¸  Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"âœ… Environment setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project-structure"
      },
      "source": [
        "## ğŸ“ Project Structure Setup\n",
        "\n",
        "Create the necessary directories and core functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "create-directories",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20756d5-269f-4eda-c3ea-c3ae05f2b59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Project directories created\n"
          ]
        }
      ],
      "source": [
        "# Create project directories\n",
        "directories = [\n",
        "    'data/processed',\n",
        "    'data/raw',\n",
        "    'data/results',\n",
        "    'models',\n",
        "    'logs',\n",
        "    'src/domain_generator/models',\n",
        "    'src/domain_generator/data',\n",
        "    'src/domain_generator/evaluation',\n",
        "    'src/domain_generator/safety',\n",
        "    'src/domain_generator/utils'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(\"ğŸ“ Project directories created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "core-classes"
      },
      "source": [
        "## ğŸ§  Core Domain Generator Classes\n",
        "\n",
        "Implement the main functionality for training and inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "config-class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b6a778-c658-491c-aeee-199fbf447739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš™ï¸  Configuration classes defined\n"
          ]
        }
      ],
      "source": [
        "# Configuration class\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Model configuration\"\"\"\n",
        "    model_name: str = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "    cache_dir: str = \"./cache\"\n",
        "    max_length: int = 512\n",
        "    temperature: float = 0.7\n",
        "    top_p: float = 0.9\n",
        "    top_k: int = 50\n",
        "\n",
        "@dataclass\n",
        "class LoRAConfig:\n",
        "    \"\"\"LoRA configuration for efficient training\"\"\"\n",
        "    r: int = 16\n",
        "    lora_alpha: int = 32\n",
        "    lora_dropout: float = 0.1\n",
        "    target_modules: List[str] = field(default_factory=lambda: [\"q_proj\", \"v_proj\"])\n",
        "    bias: str = \"none\"\n",
        "    task_type: str = \"CAUSAL_LM\"\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"Training configuration\"\"\"\n",
        "    batch_size: int = 4\n",
        "    gradient_accumulation_steps: int = 4\n",
        "    num_epochs: int = 3\n",
        "    learning_rate: float = 2e-4\n",
        "    weight_decay: float = 0.01\n",
        "    warmup_ratio: float = 0.1\n",
        "    max_grad_norm: float = 1.0\n",
        "    logging_steps: int = 10\n",
        "    save_steps: int = 500\n",
        "    eval_steps: int = 500\n",
        "    fp16: bool = True\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Main configuration class\"\"\"\n",
        "    model: ModelConfig = field(default_factory=ModelConfig)\n",
        "    lora: LoRAConfig = field(default_factory=LoRAConfig)\n",
        "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
        "    device: str = field(default_factory=lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"âš™ï¸  Configuration classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "model-configs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aec799d-df8a-4e0d-a80e-0d03145de0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Model configurations defined\n"
          ]
        }
      ],
      "source": [
        "# Model configurations\n",
        "def create_model_configs():\n",
        "    \"\"\"Create model configurations optimized for Colab\"\"\"\n",
        "    return {\n",
        "        \"llama-3.2-1b\": {\n",
        "            \"model_name\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
        "            \"lora_config\": LoRAConfig(\n",
        "                r=16,\n",
        "                lora_alpha=32,\n",
        "                target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        "            ),\n",
        "            \"training_config\": TrainingConfig(\n",
        "                batch_size=2,  # Reduced for Colab\n",
        "                gradient_accumulation_steps=8,\n",
        "                num_epochs=3,\n",
        "                learning_rate=2e-4\n",
        "            )\n",
        "        },\n",
        "        \"phi-3-mini\": {\n",
        "            \"model_name\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "            \"lora_config\": LoRAConfig(\n",
        "                r=16,\n",
        "                lora_alpha=32,\n",
        "                target_modules=[\"qkv_proj\", \"o_proj\"]\n",
        "            ),\n",
        "            \"training_config\": TrainingConfig(\n",
        "                batch_size=2,\n",
        "                gradient_accumulation_steps=8,\n",
        "                num_epochs=3,\n",
        "                learning_rate=1e-4\n",
        "            )\n",
        "        },\n",
        "        \"distilgpt2\": {\n",
        "            \"model_name\": \"distilgpt2\",\n",
        "            \"lora_config\": LoRAConfig(\n",
        "                r=8,\n",
        "                lora_alpha=16,\n",
        "                target_modules=[\"c_attn\", \"c_proj\"]\n",
        "            ),\n",
        "            \"training_config\": TrainingConfig(\n",
        "                batch_size=4,\n",
        "                gradient_accumulation_steps=4,\n",
        "                num_epochs=5,\n",
        "                learning_rate=3e-4\n",
        "            )\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"ğŸ¯ Model configurations defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "trainer-class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c01ce32-6f83-4e41-e40f-78e648399a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‹ï¸ DomainGeneratorTrainer class defined\n"
          ]
        }
      ],
      "source": [
        "# Domain Generator Trainer\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig as PeftLoraConfig, get_peft_model, TaskType\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class DomainGeneratorTrainer:\n",
        "    \"\"\"Domain generation model trainer\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "\n",
        "    def _load_model_and_tokenizer(self, model_name: str):\n",
        "        \"\"\"Load model and tokenizer\"\"\"\n",
        "        print(f\"ğŸ“¥ Loading model: {model_name}\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_name,\n",
        "            cache_dir=self.config.model.cache_dir,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Set pad token\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Load model\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            cache_dir=self.config.model.cache_dir,\n",
        "            torch_dtype=torch.float16 if self.config.training.fp16 else torch.float32,\n",
        "            trust_remote_code=True,\n",
        "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Model loaded: {model_name}\")\n",
        "\n",
        "    def _setup_lora(self):\n",
        "        \"\"\"Setup LoRA for efficient training\"\"\"\n",
        "        print(\"ğŸ”§ Setting up LoRA...\")\n",
        "\n",
        "        peft_config = PeftLoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            r=self.config.lora.r,\n",
        "            lora_alpha=self.config.lora.lora_alpha,\n",
        "            lora_dropout=self.config.lora.lora_dropout,\n",
        "            target_modules=self.config.lora.target_modules,\n",
        "            bias=self.config.lora.bias\n",
        "        )\n",
        "\n",
        "        self.model = get_peft_model(self.model, peft_config)\n",
        "        self.model.print_trainable_parameters()\n",
        "\n",
        "        print(\"âœ… LoRA setup complete\")\n",
        "\n",
        "    def _prepare_dataset(self, dataset_path: str):\n",
        "        \"\"\"Prepare training dataset\"\"\"\n",
        "        print(f\"ğŸ“Š Loading dataset: {dataset_path}\")\n",
        "\n",
        "        # Load dataset\n",
        "        with open(dataset_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Convert to training format\n",
        "        texts = []\n",
        "        for item in data:\n",
        "            if isinstance(item, dict) and 'text' in item:\n",
        "                texts.append(item['text'])\n",
        "            elif isinstance(item, str):\n",
        "                texts.append(item)\n",
        "\n",
        "        print(f\"ğŸ“ˆ Dataset size: {len(texts)} examples\")\n",
        "\n",
        "        # Tokenize\n",
        "        def tokenize_function(examples):\n",
        "            return self.tokenizer(\n",
        "                examples['text'],\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                max_length=self.config.model.max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = Dataset.from_dict({'text': texts})\n",
        "        tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "        return tokenized_dataset\n",
        "\n",
        "    def train(self, dataset_path: str, output_dir: str, model_name: str = None) -> str:\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        if model_name is None:\n",
        "            model_name = self.config.model.model_name\n",
        "\n",
        "        # Load model and tokenizer\n",
        "        self._load_model_and_tokenizer(model_name)\n",
        "\n",
        "        # Setup LoRA\n",
        "        self._setup_lora()\n",
        "\n",
        "        # Prepare dataset\n",
        "        train_dataset = self._prepare_dataset(dataset_path)\n",
        "\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            per_device_train_batch_size=self.config.training.batch_size,\n",
        "            gradient_accumulation_steps=self.config.training.gradient_accumulation_steps,\n",
        "            num_train_epochs=self.config.training.num_epochs,\n",
        "            learning_rate=self.config.training.learning_rate,\n",
        "            weight_decay=self.config.training.weight_decay,\n",
        "            warmup_ratio=self.config.training.warmup_ratio,\n",
        "            max_grad_norm=self.config.training.max_grad_norm,\n",
        "            logging_steps=self.config.training.logging_steps,\n",
        "            save_steps=self.config.training.save_steps,\n",
        "            fp16=self.config.training.fp16,\n",
        "            dataloader_pin_memory=False,\n",
        "            remove_unused_columns=False,\n",
        "            report_to=None  # Disable wandb for Colab\n",
        "        )\n",
        "\n",
        "        # Data collator\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=self.tokenizer,\n",
        "            mlm=False\n",
        "        )\n",
        "\n",
        "        # Initialize trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            data_collator=data_collator,\n",
        "            tokenizer=self.tokenizer\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        print(\"ğŸš€ Starting training...\")\n",
        "        trainer.train()\n",
        "\n",
        "        # Save model\n",
        "        trainer.save_model()\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        print(f\"âœ… Training complete: {output_dir}\")\n",
        "        return output_dir\n",
        "\n",
        "print(\"ğŸ‹ï¸ DomainGeneratorTrainer class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "inference-class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7aff58-f195-49a6-b0ec-0435597767bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”® DomainGenerator inference class defined\n"
          ]
        }
      ],
      "source": [
        "# Domain Generator for Inference\n",
        "from transformers import pipeline\n",
        "from peft import PeftModel\n",
        "import re\n",
        "\n",
        "class DomainGenerator:\n",
        "    \"\"\"Domain name generator for inference\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str, base_model_name: str, config: Config):\n",
        "        self.config = config\n",
        "        self.model_path = model_path\n",
        "        self.base_model_name = base_model_name\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the trained model\"\"\"\n",
        "        print(f\"ğŸ“¥ Loading trained model from: {self.model_path}\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Load base model\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model_name,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
        "        )\n",
        "\n",
        "        # Load LoRA weights\n",
        "        self.model = PeftModel.from_pretrained(base_model, self.model_path)\n",
        "        self.model.eval()\n",
        "\n",
        "        print(\"âœ… Model loaded successfully\")\n",
        "\n",
        "    def _create_prompt(self, business_description: str, target_audience: str = None) -> str:\n",
        "        \"\"\"Create prompt for domain generation\"\"\"\n",
        "        if target_audience:\n",
        "            prompt = f\"Business: {business_description}\\nTarget Audience: {target_audience}\\nDomain suggestions:\\n\"\n",
        "        else:\n",
        "            prompt = f\"Business: {business_description}\\nDomain suggestions:\\n\"\n",
        "        return prompt\n",
        "\n",
        "    def _extract_domains(self, generated_text: str) -> List[str]:\n",
        "        \"\"\"Extract domain names from generated text\"\"\"\n",
        "        # Simple domain extraction using regex\n",
        "        domain_pattern = r'\\b[a-zA-Z0-9][a-zA-Z0-9-]*[a-zA-Z0-9]*\\.[a-z]{2,}\\b'\n",
        "        domains = re.findall(domain_pattern, generated_text.lower())\n",
        "\n",
        "        # Remove duplicates and filter\n",
        "        unique_domains = []\n",
        "        for domain in domains:\n",
        "            if domain not in unique_domains and len(domain) > 4:\n",
        "                unique_domains.append(domain)\n",
        "\n",
        "        return unique_domains[:10]  # Return top 10\n",
        "\n",
        "    def generate_domains(\n",
        "        self,\n",
        "        business_description: str,\n",
        "        target_audience: str = None,\n",
        "        num_suggestions: int = 5,\n",
        "        temperature: float = 0.7\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Generate domain name suggestions\"\"\"\n",
        "        prompt = self._create_prompt(business_description, target_audience)\n",
        "\n",
        "        # Tokenize input\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=200,\n",
        "                temperature=temperature,\n",
        "                top_p=self.config.model.top_p,\n",
        "                top_k=self.config.model.top_k,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.pad_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode\n",
        "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_part = generated_text[len(prompt):]\n",
        "\n",
        "        # Extract domains\n",
        "        domains = self._extract_domains(generated_part)\n",
        "\n",
        "        return domains[:num_suggestions]\n",
        "\n",
        "    def generate_with_confidence(\n",
        "        self,\n",
        "        business_description: str,\n",
        "        target_audience: str = None,\n",
        "        num_suggestions: int = 5\n",
        "    ) -> List[Dict[str, Union[str, float]]]:\n",
        "        \"\"\"Generate domains with confidence scores\"\"\"\n",
        "        domains = self.generate_domains(business_description, target_audience, num_suggestions)\n",
        "\n",
        "        # Mock confidence scores (in a real implementation, you'd calculate these)\n",
        "        results = []\n",
        "        for i, domain in enumerate(domains):\n",
        "            confidence = max(0.5, 0.9 - (i * 0.1) + random.uniform(-0.05, 0.05))\n",
        "            results.append({\n",
        "                \"domain\": domain,\n",
        "                \"confidence\": round(confidence, 2)\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "print(\"ğŸ”® DomainGenerator inference class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "main-wrapper"
      },
      "source": [
        "## ğŸ¯ Main Jupyter Wrapper Class\n",
        "\n",
        "This provides the same interface as the CLI version, optimized for Jupyter notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jupyter-wrapper",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd318f3-4352-4c60-8335-ad7d14197b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ JupyterDomainGenerator class defined\n"
          ]
        }
      ],
      "source": [
        "class JupyterDomainGenerator:\n",
        "    \"\"\"Jupyter-friendly wrapper for domain generation\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"llama-3.2-1b\") -> None:\n",
        "        \"\"\"Initialize the domain generator for Jupyter use.\n",
        "\n",
        "        Args:\n",
        "            model_name: Model configuration to use\n",
        "        \"\"\"\n",
        "        self.config = Config()\n",
        "        self.model_name = model_name\n",
        "        self.model_configs = create_model_configs()\n",
        "        self.trainer: Optional[DomainGeneratorTrainer] = None\n",
        "        self.generator: Optional[DomainGenerator] = None\n",
        "\n",
        "        # Set up model configuration\n",
        "        if model_name in self.model_configs:\n",
        "            model_config = self.model_configs[model_name]\n",
        "            self.config.model.model_name = model_config[\"model_name\"]\n",
        "            self.config.lora = model_config[\"lora_config\"]\n",
        "            self.config.training = model_config[\"training_config\"]\n",
        "        else:\n",
        "            available_models = list(self.model_configs.keys())\n",
        "            raise ValueError(f\"Model '{model_name}' not found. Available: {available_models}\")\n",
        "\n",
        "    def create_sample_dataset(self, output_path: str = \"data/processed/training_dataset.json\") -> str:\n",
        "        \"\"\"Create a sample training dataset\"\"\"\n",
        "        print(\"ğŸ“ Creating sample training dataset...\")\n",
        "\n",
        "        sample_data = [\n",
        "            {\"text\": \"Business: AI-powered restaurant management platform\\nTarget Audience: small business owners\\nDomain suggestions:\\n1. restroai.com\\n2. kitcheniq.io\\n3. smartbites.co\\n4. menumaster.app\\n5. restotech.com\"},\n",
        "            {\"text\": \"Business: eco-friendly clothing brand\\nTarget Audience: millennials\\nDomain suggestions:\\n1. greenthreads.com\\n2. ecowear.io\\n3. sustainablestyle.co\\n4. earthfashion.com\\n5. consciouscloset.com\"},\n",
        "            {\"text\": \"Business: virtual reality gaming arcade\\nTarget Audience: gamers\\nDomain suggestions:\\n1. vrzone.com\\n2. virtualplay.io\\n3. immersivegames.co\\n4. vrgalaxy.com\\n5. futurearcade.com\"},\n",
        "            {\"text\": \"Business: online tutoring platform\\nTarget Audience: students\\nDomain suggestions:\\n1. smarttutor.com\\n2. learnhub.io\\n3. studyboost.co\\n4. tutorai.com\\n5. brainbridge.com\"},\n",
        "            {\"text\": \"Business: fitness tracking mobile app\\nTarget Audience: health enthusiasts\\nDomain suggestions:\\n1. fittrack.com\\n2. healthpulse.io\\n3. workoutwise.co\\n4. bodymetrics.com\\n5. fitnessflow.com\"}\n",
        "        ]\n",
        "\n",
        "        # Expand dataset with variations\n",
        "        expanded_data = []\n",
        "        for item in sample_data:\n",
        "            expanded_data.append(item)\n",
        "            # Add variations\n",
        "            for i in range(3):\n",
        "                expanded_data.append(item)  # Simple repetition for now\n",
        "\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(expanded_data, f, indent=2)\n",
        "\n",
        "        print(f\"âœ… Sample dataset created: {output_path} ({len(expanded_data)} examples)\")\n",
        "        return output_path\n",
        "\n",
        "    def train_model(\n",
        "        self,\n",
        "        dataset_path: str = None,\n",
        "        output_dir: Optional[str] = None,\n",
        "        create_sample_data: bool = True\n",
        "    ) -> str:\n",
        "        \"\"\"Train a domain generation model.\"\"\"\n",
        "        if output_dir is None:\n",
        "            output_dir = f\"models/{self.model_name}-domain-generator\"\n",
        "\n",
        "        # Create sample dataset if needed\n",
        "        if dataset_path is None:\n",
        "            dataset_path = \"data/processed/training_dataset.json\"\n",
        "\n",
        "        if create_sample_data or not os.path.exists(dataset_path):\n",
        "            dataset_path = self.create_sample_dataset(dataset_path)\n",
        "\n",
        "        # Initialize trainer\n",
        "        self.trainer = DomainGeneratorTrainer(self.config)\n",
        "\n",
        "        # Train model\n",
        "        print(f\"ğŸš€ Starting training with {self.model_name}\")\n",
        "        print(f\"ğŸ“Š Model: {self.config.model.model_name}\")\n",
        "        print(f\"ğŸ’¾ Output: {output_dir}\")\n",
        "        print(f\"ğŸ”§ Device: {self.config.device}\")\n",
        "\n",
        "        model_path = self.trainer.train(\n",
        "            dataset_path=dataset_path,\n",
        "            output_dir=output_dir,\n",
        "            model_name=self.config.model.model_name\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… Training completed: {model_path}\")\n",
        "        return model_path\n",
        "\n",
        "    def load_model(self, model_path: str) -> None:\n",
        "        \"\"\"Load a trained model for inference.\"\"\"\n",
        "        print(f\"ğŸ“¥ Loading model from: {model_path}\")\n",
        "\n",
        "        self.generator = DomainGenerator(\n",
        "            model_path=model_path,\n",
        "            base_model_name=self.config.model.model_name,\n",
        "            config=self.config\n",
        "        )\n",
        "\n",
        "        print(\"âœ… Model loaded successfully\")\n",
        "\n",
        "    def generate_domains(\n",
        "        self,\n",
        "        business_description: str,\n",
        "        target_audience: Optional[str] = None,\n",
        "        num_suggestions: int = 5,\n",
        "        temperature: float = 0.7,\n",
        "        with_confidence: bool = True\n",
        "    ) -> Union[List[str], List[Dict[str, float]]]:\n",
        "        \"\"\"Generate domain name suggestions.\"\"\"\n",
        "        if self.generator is None:\n",
        "            raise ValueError(\"No model loaded. Call load_model() first.\")\n",
        "\n",
        "        if with_confidence:\n",
        "            return self.generator.generate_with_confidence(\n",
        "                business_description=business_description,\n",
        "                target_audience=target_audience,\n",
        "                num_suggestions=num_suggestions\n",
        "            )\n",
        "        else:\n",
        "            return self.generator.generate_domains(\n",
        "                business_description=business_description,\n",
        "                target_audience=target_audience,\n",
        "                num_suggestions=num_suggestions,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "    def quick_demo(self, business_description: str = None) -> None:\n",
        "        \"\"\"Run a quick demo with a sample business description.\"\"\"\n",
        "        if business_description is None:\n",
        "            business_description = \"innovative AI-powered restaurant management platform for small businesses\"\n",
        "\n",
        "        print(f\"ğŸ” Generating domains for: {business_description}\")\n",
        "\n",
        "        # Try to use existing model or create a simple demo\n",
        "        if self.generator is None:\n",
        "            print(\"âš ï¸  No trained model loaded. This would normally require a trained model.\")\n",
        "            print(\"ğŸ“ Expected output format:\")\n",
        "            sample_domains = [\n",
        "                {\"domain\": \"restroai.com\", \"confidence\": 0.85},\n",
        "                {\"domain\": \"kitcheniq.io\", \"confidence\": 0.78},\n",
        "                {\"domain\": \"smartbites.co\", \"confidence\": 0.72},\n",
        "                {\"domain\": \"menumaster.app\", \"confidence\": 0.69},\n",
        "                {\"domain\": \"restotech.com\", \"confidence\": 0.65}\n",
        "            ]\n",
        "\n",
        "            for i, suggestion in enumerate(sample_domains, 1):\n",
        "                print(f\"  {i}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "        else:\n",
        "            suggestions = self.generate_domains(business_description)\n",
        "            for i, suggestion in enumerate(suggestions, 1):\n",
        "                if isinstance(suggestion, dict):\n",
        "                    print(f\"  {i}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "                else:\n",
        "                    print(f\"  {i}. {suggestion}\")\n",
        "\n",
        "    def get_model_info(self) -> Dict[str, str]:\n",
        "        \"\"\"Get information about the current model configuration.\"\"\"\n",
        "        return {\n",
        "            \"model_name\": self.model_name,\n",
        "            \"base_model\": self.config.model.model_name,\n",
        "            \"device\": self.config.device,\n",
        "            \"parameters\": self._get_model_size(),\n",
        "            \"colab_optimized\": \"Yes\"\n",
        "        }\n",
        "\n",
        "    def _get_model_size(self) -> str:\n",
        "        \"\"\"Get approximate model size information.\"\"\"\n",
        "        size_map = {\n",
        "            \"meta-llama/Llama-3.2-1B-Instruct\": \"1B (~3.5GB)\",\n",
        "            \"microsoft/Phi-3-mini-4k-instruct\": \"3.8B (~3.8GB)\",\n",
        "            \"distilgpt2\": \"82M (~330MB)\"\n",
        "        }\n",
        "        return size_map.get(self.config.model.model_name, \"Unknown\")\n",
        "\n",
        "    def list_available_models(self) -> List[str]:\n",
        "        \"\"\"List all available model configurations.\"\"\"\n",
        "        return list(self.model_configs.keys())\n",
        "\n",
        "# Convenience functions\n",
        "def create_generator(model_name: str = \"llama-3.2-1b\") -> JupyterDomainGenerator:\n",
        "    \"\"\"Create a Jupyter-compatible domain generator.\"\"\"\n",
        "    return JupyterDomainGenerator(model_name)\n",
        "\n",
        "def quick_start_demo() -> None:\n",
        "    \"\"\"Run a quick demonstration of the domain generator.\"\"\"\n",
        "    print(\"ğŸš€ Domain Name Generator - Colab Edition\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Show available models\n",
        "    generator = JupyterDomainGenerator()\n",
        "    models = generator.list_available_models()\n",
        "    print(f\"ğŸ“± Available models: {', '.join(models)}\")\n",
        "\n",
        "    # Show model info\n",
        "    info = generator.get_model_info()\n",
        "    print(f\"ğŸ”§ Current model: {info['base_model']}\")\n",
        "    print(f\"ğŸ’¾ Model size: {info['parameters']}\")\n",
        "    print(f\"ğŸ–¥ï¸  Device: {info['device']}\")\n",
        "    print(f\"â˜ï¸  Colab optimized: {info['colab_optimized']}\")\n",
        "\n",
        "    # Run demo\n",
        "    print(\"\\nğŸ¯ Sample Generation:\")\n",
        "    generator.quick_demo()\n",
        "\n",
        "    print(\"\\nğŸ’¡ To get started:\")\n",
        "    print(\"  1. generator = create_generator('distilgpt2')     # Start with smallest model\")\n",
        "    print(\"  2. model_path = generator.train_model()          # Train on sample data\")\n",
        "    print(\"  3. generator.load_model(model_path)              # Load trained model\")\n",
        "    print(\"  4. domains = generator.generate_domains('your business description')\")\n",
        "    print(\"\\nğŸ”§ Recommended models for Colab: distilgpt2 (fastest), llama-3.2-1b (best quality)\")\n",
        "\n",
        "print(\"ğŸ¯ JupyterDomainGenerator class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo-section"
      },
      "source": [
        "## ğŸš€ Quick Start Demo\n",
        "\n",
        "Run this to see the domain generator in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "run-demo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debbfe23-33d0-4474-e859-7114a472cfd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Domain Name Generator - Colab Edition\n",
            "==================================================\n",
            "ğŸ“± Available models: llama-3.2-1b, phi-3-mini, distilgpt2\n",
            "ğŸ”§ Current model: meta-llama/Llama-3.2-1B-Instruct\n",
            "ğŸ’¾ Model size: 1B (~3.5GB)\n",
            "ğŸ–¥ï¸  Device: cuda\n",
            "â˜ï¸  Colab optimized: Yes\n",
            "\n",
            "ğŸ¯ Sample Generation:\n",
            "ğŸ” Generating domains for: innovative AI-powered restaurant management platform for small businesses\n",
            "âš ï¸  No trained model loaded. This would normally require a trained model.\n",
            "ğŸ“ Expected output format:\n",
            "  1. restroai.com (confidence: 0.85)\n",
            "  2. kitcheniq.io (confidence: 0.78)\n",
            "  3. smartbites.co (confidence: 0.72)\n",
            "  4. menumaster.app (confidence: 0.69)\n",
            "  5. restotech.com (confidence: 0.65)\n",
            "\n",
            "ğŸ’¡ To get started:\n",
            "  1. generator = create_generator('distilgpt2')     # Start with smallest model\n",
            "  2. model_path = generator.train_model()          # Train on sample data\n",
            "  3. generator.load_model(model_path)              # Load trained model\n",
            "  4. domains = generator.generate_domains('your business description')\n",
            "\n",
            "ğŸ”§ Recommended models for Colab: distilgpt2 (fastest), llama-3.2-1b (best quality)\n"
          ]
        }
      ],
      "source": [
        "# Run the quick start demo\n",
        "quick_start_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-section"
      },
      "source": [
        "## ğŸ‹ï¸ Model Training\n",
        "\n",
        "Train your own domain generation model. Start with DistilGPT2 for faster training on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "train-model",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9328effbf2494551aed86b8efe53009f",
            "91136012d20b40b48cf58fcead82bace",
            "1a718a0220954fb689749af0f3225f33",
            "689a401a051047b8a5367cff9a71fb74",
            "356c747281fb47d5878a78b8a9dd0856",
            "569c14305ace47438065fca4745fd108",
            "a3e37f2d829447e6825b690a7edde1a7",
            "b9d1c2568ca941349d46b7ffec5e08ba",
            "995d83ed073c46eb83a4abeafbd19a31",
            "bb84084d0e9641a1bfa001f476151556",
            "f171d1f6da7240878923a91db5c4c927",
            "5a3bfbc10cb4489da04d160c08944aa0",
            "42fb24029b1148459080c1c4d1b4667c",
            "0288f5c7e9114fd8b5fa3fa5591b63c1",
            "33ef2c645d7c4f85b669a30285219462",
            "de15329451774602be0c06b77c886da0",
            "a3b0a8fa01db4eeeb8b487a371c0b609",
            "41a03e7373374d93a0c94b3e4e59bbf6",
            "b98f719267fb4e59945c6ef1291477a6",
            "998743c7aade46c1867040cf8525d69a",
            "0bb2672e4b5644a6b28b5936232eb082",
            "4eb4f9e8b44646b1b524a55642126eff",
            "24bdbf5001fc4396a3477dbf2e6dc1ad",
            "0b53912b45534b7cb0cbf6e4746e2615",
            "74cb3054c7bb49d0aefd3e2d85a2ca53",
            "31449ddacd2b45348fe4909120b860f4",
            "c423cef1028b4a4c91a039b3bb442686",
            "09c03a16be6649c2ae0b83fa8ff5ee21",
            "8a9e47c7437d42c98e5769de5a39990b",
            "ae8f82024a704d28bfca3a477ab5cffd",
            "ca33f79ee75c4c498dc34dc495d60084",
            "e2b5e38e954e4e1ba035ccc39217fb75",
            "c3471e5390cf4dedad5f727ffe34a394",
            "7646620eb2574b0e8ed6fba8768bf89f",
            "80404245b0bb49fcb72ca4f85387bc7e",
            "4d6c0f533765473cb5003702298a4bc4",
            "6be5e4d3f79e4614b301eb4d6b4db3c1",
            "61988e5bd4a34d3db71e36ef5ba00c80",
            "4a813a2e321748d19ddfc2de1f34d44c",
            "be4eb86220e044f9a3e5ac902c1aed66",
            "3a69c5321a0a49359fa45693a8f2cbae",
            "688f07cfa5d34b3fb16486c37d89def1",
            "c4e5767343fd4adabca2efdd3d3b4aef",
            "5ff6381930bc417e948eef3747d8ea19",
            "83e9840dc4ef4468a60c1d405c9ee2b2",
            "c9dd3b1d56b84f0b89e41a0dbed22308",
            "bfe4484b2fcc43f2a4953565ec586e13",
            "66d9267d59ff4df188dd3f58f291c148",
            "6ab932c2f7d44a8495c4a96d1af1cbb5",
            "7435af55dce640d2be25067a2e91a00a",
            "f666a0a861dd4542a9c25c89d9adc3ad",
            "c9a5f7a7f7644f45b081a72bc80a90e4",
            "6f53ee284aca448288dda9c25bd69cd1",
            "ade627379b914b22926ae792d3c32a09",
            "1ea74fa0731c4cd69bdc19f5a5fed73f",
            "35bee5692f28415589540a2b54c50ad2",
            "cfd009e8e2504c5db03c86d271b1b75c",
            "1269e547372e4f23831e46ce4fa1299e",
            "73840f7eaff64d81ab93d979ee7dd1c6",
            "ae07bf82ade7455ab1db9b0d852259d3",
            "db3e4a78bd5a46dab208e4c17c4dcddc",
            "5cfd4045103a46319269224f064ae749",
            "3b4c403bf5ca426686764e5fa3a3f11c",
            "982eccda1da44db9838c7b4bd5865ad2",
            "5452a66bc60a4f70a40c3ae2b46a6f06",
            "0f1aa32402554ebfb92d3680936203bb",
            "2efc7cb180f54ca3a67908b6d65c092a",
            "968c7751138d45b2bd10718ba8718595",
            "62ab47d99076450badb5ccb8207e5a55",
            "3b890aa9ee5140e3b7437f4e19e630e8",
            "2d8eb25cd5774755946bf6cd0190f0ae",
            "39fc0ba8ce5c40a5a6b389932f9fa994",
            "788015dfa7f74bd788df055ceab79139",
            "1f4a953f82324c828f4de98dcc65a038",
            "2edf272357044b4883ca8476fd0f5f83",
            "8255074ac8f240549a6ef636b505eff1",
            "41eb2ef19f5e4a6bb8a24b4d94427859",
            "636615a8120640db9951428d3a7932bf",
            "45be3ed3054648f8866ec9e9f4336223",
            "334c250e58464f23aa77c828c9cbb4aa",
            "4b5ab42884634828a7e80e8c103d6626",
            "54bb7bcd62f843638807b29d679c557f",
            "8c1da590a07b42a7a5e748f049f954db",
            "ead32ed8872241b48294a36185674dcd",
            "abc4a43ff07b4f7094eba7a7d22b9565",
            "50318cea4a514198808921dbeeb33b11",
            "f2ecb40c621c4a40b62fac74e6cc379a",
            "838094ccef244d7fb5c1b38c78a9736d"
          ]
        },
        "outputId": "966ccbc6-5677-43e0-9bb5-d5da47f7b488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Creating domain generator with DistilGPT2 (fastest for Colab)\n",
            "\n",
            "ğŸ“Š Model Info:\n",
            "  model_name: distilgpt2\n",
            "  base_model: distilgpt2\n",
            "  device: cuda\n",
            "  parameters: 82M (~330MB)\n",
            "  colab_optimized: Yes\n",
            "\n",
            "ğŸš€ Starting training...\n",
            "â±ï¸  This will take 5-10 minutes on Colab GPU\n",
            "ğŸ“ Creating sample training dataset...\n",
            "âœ… Sample dataset created: data/processed/training_dataset.json (20 examples)\n",
            "ğŸš€ Starting training with distilgpt2\n",
            "ğŸ“Š Model: distilgpt2\n",
            "ğŸ’¾ Output: models/distilgpt2-domain-generator\n",
            "ğŸ”§ Device: cuda\n",
            "ğŸ“¥ Loading model: distilgpt2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9328effbf2494551aed86b8efe53009f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a3bfbc10cb4489da04d160c08944aa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24bdbf5001fc4396a3477dbf2e6dc1ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7646620eb2574b0e8ed6fba8768bf89f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e9840dc4ef4468a60c1d405c9ee2b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35bee5692f28415589540a2b54c50ad2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2efc7cb180f54ca3a67908b6d65c092a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded: distilgpt2\n",
            "ğŸ”§ Setting up LoRA...\n",
            "trainable params: 405,504 || all params: 82,318,080 || trainable%: 0.4926\n",
            "âœ… LoRA setup complete\n",
            "ğŸ“Š Loading dataset: data/processed/training_dataset.json\n",
            "ğŸ“ˆ Dataset size: 20 examples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "636615a8120640db9951428d3a7932bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaulinocristovao86\u001b[0m (\u001b[33mpaulinocristovao86-university-of-tsukuba\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250731_082807-k6m7cnyi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/paulinocristovao86-university-of-tsukuba/huggingface/runs/k6m7cnyi' target=\"_blank\">models/distilgpt2-domain-generator</a></strong> to <a href='https://wandb.ai/paulinocristovao86-university-of-tsukuba/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/paulinocristovao86-university-of-tsukuba/huggingface' target=\"_blank\">https://wandb.ai/paulinocristovao86-university-of-tsukuba/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/paulinocristovao86-university-of-tsukuba/huggingface/runs/k6m7cnyi' target=\"_blank\">https://wandb.ai/paulinocristovao86-university-of-tsukuba/huggingface/runs/k6m7cnyi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-316318498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"â±ï¸  This will take 5-10 minutes on Colab GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nâœ… Training completed! Model saved to: {model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-350530862.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, dataset_path, output_dir, create_sample_data)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ğŸ”§ Device: {self.config.device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         model_path = self.trainer.train(\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-481685192.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset_path, output_dir, model_name)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ğŸš€ Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2238\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2530\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5343\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5344\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5345\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             batch = pad_without_fast_tokenizer_warning(\n\u001b[0m\u001b[1;32m   1015\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpad_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Restore the state of the warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3371\u001b[0m                 \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3375\u001b[0m     def create_token_type_ids_from_sequences(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    781\u001b[0m                         \u001b[0;34m\"Please see if a fast version of this tokenizer is available to have this feature available.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                     ) from e\n\u001b[0;32m--> 783\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding with\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;34m\" 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
          ]
        }
      ],
      "source": [
        "# Create and train a model (start with distilgpt2 for speed)\n",
        "print(\"ğŸ¯ Creating domain generator with DistilGPT2 (fastest for Colab)\")\n",
        "generator = create_generator('distilgpt2')\n",
        "\n",
        "# Show model info\n",
        "info = generator.get_model_info()\n",
        "print(f\"\\nğŸ“Š Model Info:\")\n",
        "for key, value in info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nğŸš€ Starting training...\")\n",
        "print(\"â±ï¸  This will take 5-10 minutes on Colab GPU\")\n",
        "\n",
        "model_path = generator.train_model()\n",
        "print(f\"\\nâœ… Training completed! Model saved to: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inference-section"
      },
      "source": [
        "## ğŸ”® Domain Generation\n",
        "\n",
        "Use your trained model to generate domain suggestions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-and-generate"
      },
      "outputs": [],
      "source": [
        "# Load the trained model (use the model_path from training above)\n",
        "print(\"ğŸ“¥ Loading trained model...\")\n",
        "try:\n",
        "    generator.load_model(model_path)\n",
        "    print(\"âœ… Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Error loading model: {e}\")\n",
        "    print(\"Running demo mode instead...\")\n",
        "    generator.quick_demo()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate-examples"
      },
      "outputs": [],
      "source": [
        "# Generate domain suggestions for different business types\n",
        "test_businesses = [\n",
        "    \"AI-powered fitness tracking app for runners\",\n",
        "    \"eco-friendly meal delivery service\",\n",
        "    \"online coding bootcamp for beginners\",\n",
        "    \"virtual interior design consultancy\",\n",
        "    \"blockchain-based supply chain management\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ” Generating domain suggestions for different businesses:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, business in enumerate(test_businesses, 1):\n",
        "    print(f\"\\n{i}. {business}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    try:\n",
        "        if generator.generator is not None:\n",
        "            suggestions = generator.generate_domains(\n",
        "                business_description=business,\n",
        "                num_suggestions=3,\n",
        "                with_confidence=True\n",
        "            )\n",
        "\n",
        "            for j, suggestion in enumerate(suggestions, 1):\n",
        "                if isinstance(suggestion, dict):\n",
        "                    print(f\"   {j}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "                else:\n",
        "                    print(f\"   {j}. {suggestion}\")\n",
        "        else:\n",
        "            # Demo mode - show expected format\n",
        "            print(\"   (Demo mode - sample suggestions)\")\n",
        "            sample_domains = [f\"example{i}_{j}.com\" for j in range(1, 4)]\n",
        "            for j, domain in enumerate(sample_domains, 1):\n",
        "                print(f\"   {j}. {domain} (confidence: {0.9 - j*0.1:.2f})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸  Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive-section"
      },
      "source": [
        "## ğŸ® Interactive Domain Generation\n",
        "\n",
        "Try generating domains for your own business ideas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive-generator"
      },
      "outputs": [],
      "source": [
        "# Interactive domain generation\n",
        "def interactive_domain_generator():\n",
        "    \"\"\"Interactive function for domain generation\"\"\"\n",
        "    print(\"ğŸ¯ Interactive Domain Generator\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"Enter your business description below:\")\n",
        "\n",
        "    # In a real Colab environment, you'd use input()\n",
        "    # For demo purposes, we'll use a sample description\n",
        "    business_description = \"sustainable fashion marketplace for vintage clothing\"\n",
        "    print(f\"Business Description: {business_description}\")\n",
        "\n",
        "    target_audience = \"fashion-conscious millennials\"\n",
        "    print(f\"Target Audience: {target_audience}\")\n",
        "\n",
        "    num_suggestions = 5\n",
        "    print(f\"Number of suggestions: {num_suggestions}\")\n",
        "\n",
        "    print(\"\\nğŸ” Generating domain suggestions...\")\n",
        "\n",
        "    try:\n",
        "        if generator.generator is not None:\n",
        "            suggestions = generator.generate_domains(\n",
        "                business_description=business_description,\n",
        "                target_audience=target_audience,\n",
        "                num_suggestions=num_suggestions,\n",
        "                with_confidence=True\n",
        "            )\n",
        "\n",
        "            print(\"\\nâœ¨ Domain Suggestions:\")\n",
        "            for i, suggestion in enumerate(suggestions, 1):\n",
        "                if isinstance(suggestion, dict):\n",
        "                    print(f\"  {i}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "                else:\n",
        "                    print(f\"  {i}. {suggestion}\")\n",
        "        else:\n",
        "            print(\"\\nâœ¨ Sample Domain Suggestions (Demo Mode):\")\n",
        "            sample_suggestions = [\n",
        "                {\"domain\": \"vintagestyle.com\", \"confidence\": 0.89},\n",
        "                {\"domain\": \"retrowear.io\", \"confidence\": 0.84},\n",
        "                {\"domain\": \"sustainablethreads.co\", \"confidence\": 0.78},\n",
        "                {\"domain\": \"ecovintage.com\", \"confidence\": 0.73},\n",
        "                {\"domain\": \"circularfashion.app\", \"confidence\": 0.68}\n",
        "            ]\n",
        "\n",
        "            for i, suggestion in enumerate(sample_suggestions, 1):\n",
        "                print(f\"  {i}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Error generating domains: {e}\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ Tips for better results:\")\n",
        "    print(\"  â€¢ Be specific about your business model\")\n",
        "    print(\"  â€¢ Include your target audience\")\n",
        "    print(\"  â€¢ Mention key features or differentiators\")\n",
        "    print(\"  â€¢ Try different temperature settings for variety\")\n",
        "\n",
        "# Run interactive generator\n",
        "interactive_domain_generator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation-section"
      },
      "source": [
        "## ğŸ“Š Model Evaluation\n",
        "\n",
        "Evaluate the performance of your trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate-model"
      },
      "outputs": [],
      "source": [
        "# Model evaluation and benchmarking\n",
        "def evaluate_model_performance():\n",
        "    \"\"\"Evaluate model performance on various metrics\"\"\"\n",
        "    print(\"ğŸ“Š Model Performance Evaluation\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Test cases for evaluation\n",
        "    test_cases = [\n",
        "        \"innovative coffee shop with co-working space\",\n",
        "        \"AI-powered personal finance advisor\",\n",
        "        \"sustainable pet food subscription service\",\n",
        "        \"virtual reality fitness studio\",\n",
        "        \"blockchain-based voting platform\"\n",
        "    ]\n",
        "\n",
        "    print(f\"ğŸ¯ Testing on {len(test_cases)} business descriptions...\")\n",
        "\n",
        "    results = []\n",
        "    total_domains = 0\n",
        "\n",
        "    for i, test_case in enumerate(test_cases, 1):\n",
        "        print(f\"\\n{i}. {test_case}\")\n",
        "\n",
        "        try:\n",
        "            if generator.generator is not None:\n",
        "                import time\n",
        "                start_time = time.time()\n",
        "\n",
        "                suggestions = generator.generate_domains(\n",
        "                    business_description=test_case,\n",
        "                    num_suggestions=3,\n",
        "                    with_confidence=True\n",
        "                )\n",
        "\n",
        "                end_time = time.time()\n",
        "                generation_time = end_time - start_time\n",
        "\n",
        "                print(f\"   Generated {len(suggestions)} domains in {generation_time:.2f}s\")\n",
        "\n",
        "                for j, suggestion in enumerate(suggestions, 1):\n",
        "                    if isinstance(suggestion, dict):\n",
        "                        print(f\"     {j}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "                    else:\n",
        "                        print(f\"     {j}. {suggestion}\")\n",
        "\n",
        "                results.append({\n",
        "                    'test_case': test_case,\n",
        "                    'num_domains': len(suggestions),\n",
        "                    'generation_time': generation_time,\n",
        "                    'avg_confidence': np.mean([s.get('confidence', 0.5) if isinstance(s, dict) else 0.5 for s in suggestions])\n",
        "                })\n",
        "\n",
        "                total_domains += len(suggestions)\n",
        "\n",
        "            else:\n",
        "                print(\"   (Demo mode - using sample data)\")\n",
        "                results.append({\n",
        "                    'test_case': test_case,\n",
        "                    'num_domains': 3,\n",
        "                    'generation_time': 0.5,\n",
        "                    'avg_confidence': 0.75\n",
        "                })\n",
        "                total_domains += 3\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  Error: {e}\")\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    if results:\n",
        "        avg_generation_time = np.mean([r['generation_time'] for r in results])\n",
        "        avg_confidence = np.mean([r['avg_confidence'] for r in results])\n",
        "        avg_domains_per_request = total_domains / len(results)\n",
        "\n",
        "        print(\"\\nğŸ“ˆ Performance Summary:\")\n",
        "        print(f\"  Average generation time: {avg_generation_time:.2f}s\")\n",
        "        print(f\"  Average confidence score: {avg_confidence:.2f}\")\n",
        "        print(f\"  Average domains per request: {avg_domains_per_request:.1f}\")\n",
        "        print(f\"  Total domains generated: {total_domains}\")\n",
        "        print(f\"  Domains per second: {total_domains/sum([r['generation_time'] for r in results]):.2f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "evaluation_results = evaluate_model_performance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization-section"
      },
      "source": [
        "## ğŸ“ˆ Results Visualization\n",
        "\n",
        "Visualize the performance and results of your domain generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualize-results"
      },
      "outputs": [],
      "source": [
        "# Visualization of results\n",
        "def create_visualizations(results):\n",
        "    \"\"\"Create visualizations of model performance\"\"\"\n",
        "    if not results:\n",
        "        print(\"No results to visualize\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Domain Generator Performance Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Generation time per test case\n",
        "    test_cases = [r['test_case'][:30] + '...' if len(r['test_case']) > 30 else r['test_case'] for r in results]\n",
        "    generation_times = [r['generation_time'] for r in results]\n",
        "\n",
        "    axes[0, 0].bar(range(len(test_cases)), generation_times, color='skyblue')\n",
        "    axes[0, 0].set_title('Generation Time by Test Case')\n",
        "    axes[0, 0].set_ylabel('Time (seconds)')\n",
        "    axes[0, 0].set_xticks(range(len(test_cases)))\n",
        "    axes[0, 0].set_xticklabels(test_cases, rotation=45, ha='right')\n",
        "\n",
        "    # 2. Confidence scores\n",
        "    confidence_scores = [r['avg_confidence'] for r in results]\n",
        "    axes[0, 1].bar(range(len(test_cases)), confidence_scores, color='lightgreen')\n",
        "    axes[0, 1].set_title('Average Confidence Scores')\n",
        "    axes[0, 1].set_ylabel('Confidence')\n",
        "    axes[0, 1].set_xticks(range(len(test_cases)))\n",
        "    axes[0, 1].set_xticklabels(test_cases, rotation=45, ha='right')\n",
        "    axes[0, 1].set_ylim(0, 1)\n",
        "\n",
        "    # 3. Number of domains generated\n",
        "    num_domains = [r['num_domains'] for r in results]\n",
        "    axes[1, 0].bar(range(len(test_cases)), num_domains, color='orange')\n",
        "    axes[1, 0].set_title('Domains Generated per Test Case')\n",
        "    axes[1, 0].set_ylabel('Number of Domains')\n",
        "    axes[1, 0].set_xticks(range(len(test_cases)))\n",
        "    axes[1, 0].set_xticklabels(test_cases, rotation=45, ha='right')\n",
        "\n",
        "    # 4. Performance metrics pie chart\n",
        "    metrics = {\n",
        "        'Fast (< 1s)': sum(1 for r in results if r['generation_time'] < 1),\n",
        "        'Medium (1-3s)': sum(1 for r in results if 1 <= r['generation_time'] < 3),\n",
        "        'Slow (> 3s)': sum(1 for r in results if r['generation_time'] >= 3)\n",
        "    }\n",
        "\n",
        "    axes[1, 1].pie(metrics.values(), labels=metrics.keys(), autopct='%1.1f%%',\n",
        "                   colors=['lightcoral', 'lightsalmon', 'lightblue'])\n",
        "    axes[1, 1].set_title('Generation Speed Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Summary statistics\n",
        "    print(\"\\nğŸ“Š Summary Statistics:\")\n",
        "    print(f\"  Total test cases: {len(results)}\")\n",
        "    print(f\"  Average generation time: {np.mean(generation_times):.2f}s (Â±{np.std(generation_times):.2f})\")\n",
        "    print(f\"  Average confidence: {np.mean(confidence_scores):.3f} (Â±{np.std(confidence_scores):.3f})\")\n",
        "    print(f\"  Total domains generated: {sum(num_domains)}\")\n",
        "    print(f\"  Min/Max generation time: {min(generation_times):.2f}s / {max(generation_times):.2f}s\")\n",
        "    print(f\"  Min/Max confidence: {min(confidence_scores):.3f} / {max(confidence_scores):.3f}\")\n",
        "\n",
        "# Create visualizations\n",
        "create_visualizations(evaluation_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced-section"
      },
      "source": [
        "## ğŸ”¬ Advanced Features\n",
        "\n",
        "Explore advanced functionality like batch generation and model comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch-generation"
      },
      "outputs": [],
      "source": [
        "# Batch domain generation\n",
        "def batch_domain_generation(business_descriptions, num_suggestions=3):\n",
        "    \"\"\"Generate domains for multiple businesses at once\"\"\"\n",
        "    print(\"ğŸš€ Batch Domain Generation\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    for i, business in enumerate(business_descriptions, 1):\n",
        "        print(f\"\\n{i}. Processing: {business}\")\n",
        "\n",
        "        try:\n",
        "            if generator.generator is not None:\n",
        "                suggestions = generator.generate_domains(\n",
        "                    business_description=business,\n",
        "                    num_suggestions=num_suggestions,\n",
        "                    with_confidence=True\n",
        "                )\n",
        "                all_results[business] = suggestions\n",
        "\n",
        "                print(f\"   Generated {len(suggestions)} domains:\")\n",
        "                for j, suggestion in enumerate(suggestions, 1):\n",
        "                    if isinstance(suggestion, dict):\n",
        "                        print(f\"     {j}. {suggestion['domain']} (confidence: {suggestion['confidence']:.2f})\")\n",
        "                    else:\n",
        "                        print(f\"     {j}. {suggestion}\")\n",
        "            else:\n",
        "                # Demo mode\n",
        "                sample_suggestions = [\n",
        "                    {\"domain\": f\"demo{i}_{j}.com\", \"confidence\": 0.8 - j*0.1}\n",
        "                    for j in range(1, num_suggestions + 1)\n",
        "                ]\n",
        "                all_results[business] = sample_suggestions\n",
        "                print(f\"   (Demo) Generated {len(sample_suggestions)} domains\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸  Error: {e}\")\n",
        "            all_results[business] = []\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Test batch generation\n",
        "batch_businesses = [\n",
        "    \"smart home automation startup\",\n",
        "    \"plant-based protein powder brand\",\n",
        "    \"online language learning platform\",\n",
        "    \"sustainable packaging solutions company\",\n",
        "    \"AI-powered recruitment platform\"\n",
        "]\n",
        "\n",
        "batch_results = batch_domain_generation(batch_businesses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export-results"
      },
      "outputs": [],
      "source": [
        "# Export results to different formats\n",
        "def export_results(results, format='json'):\n",
        "    \"\"\"Export domain generation results\"\"\"\n",
        "    timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    if format.lower() == 'json':\n",
        "        filename = f\"domain_results_{timestamp}.json\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results, f, indent=2, default=str)\n",
        "        print(f\"ğŸ“„ Results exported to: {filename}\")\n",
        "\n",
        "    elif format.lower() == 'csv':\n",
        "        filename = f\"domain_results_{timestamp}.csv\"\n",
        "\n",
        "        # Flatten results for CSV\n",
        "        rows = []\n",
        "        for business, suggestions in results.items():\n",
        "            for i, suggestion in enumerate(suggestions, 1):\n",
        "                if isinstance(suggestion, dict):\n",
        "                    rows.append({\n",
        "                        'business_description': business,\n",
        "                        'rank': i,\n",
        "                        'domain': suggestion['domain'],\n",
        "                        'confidence': suggestion['confidence']\n",
        "                    })\n",
        "                else:\n",
        "                    rows.append({\n",
        "                        'business_description': business,\n",
        "                        'rank': i,\n",
        "                        'domain': suggestion,\n",
        "                        'confidence': None\n",
        "                    })\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"ğŸ“Š Results exported to: {filename}\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "# Export results in both formats\n",
        "if batch_results:\n",
        "    json_file = export_results(batch_results, 'json')\n",
        "    csv_file = export_results(batch_results, 'csv')\n",
        "\n",
        "    print(\"\\nğŸ“ Files created:\")\n",
        "    print(f\"  JSON: {json_file}\")\n",
        "    print(f\"  CSV: {csv_file}\")\n",
        "else:\n",
        "    print(\"No results to export\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion-section"
      },
      "source": [
        "## ğŸ‰ Conclusion\n",
        "\n",
        "You've successfully run the Domain Name Generator in Google Colab!\n",
        "\n",
        "### What you've accomplished:\n",
        "- âœ… Set up the complete domain generation pipeline\n",
        "- âœ… Trained a custom AI model for domain generation\n",
        "- âœ… Generated domain suggestions with confidence scores\n",
        "- âœ… Evaluated model performance\n",
        "- âœ… Created visualizations of results\n",
        "- âœ… Exported results in multiple formats\n",
        "\n",
        "### Next steps:\n",
        "1. **Try different models**: Experiment with `llama-3.2-1b` or `phi-3-mini` for better quality\n",
        "2. **Customize training data**: Create your own dataset with domain examples\n",
        "3. **Fine-tune parameters**: Adjust temperature, confidence thresholds, etc.\n",
        "4. **Scale up**: Use Colab Pro for longer training sessions\n",
        "\n",
        "### Tips for production use:\n",
        "- Use larger models for better quality\n",
        "- Implement proper domain validation\n",
        "- Add availability checking via domain APIs\n",
        "- Create a web interface for end users\n",
        "\n",
        "Happy domain generating! ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final-summary"
      },
      "outputs": [],
      "source": [
        "# Final summary and cleanup\n",
        "print(\"ğŸ¯ Domain Name Generator - Session Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Show what was accomplished\n",
        "if 'generator' in locals():\n",
        "    info = generator.get_model_info()\n",
        "    print(f\"\\nğŸ“Š Model Configuration:\")\n",
        "    for key, value in info.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "if 'evaluation_results' in locals() and evaluation_results:\n",
        "    print(f\"\\nğŸ“ˆ Performance Metrics:\")\n",
        "    avg_time = np.mean([r['generation_time'] for r in evaluation_results])\n",
        "    avg_conf = np.mean([r['avg_confidence'] for r in evaluation_results])\n",
        "    total_domains = sum([r['num_domains'] for r in evaluation_results])\n",
        "\n",
        "    print(f\"  Test cases processed: {len(evaluation_results)}\")\n",
        "    print(f\"  Average generation time: {avg_time:.2f}s\")\n",
        "    print(f\"  Average confidence: {avg_conf:.3f}\")\n",
        "    print(f\"  Total domains generated: {total_domains}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ Quick Usage Reference:\")\n",
        "print(f\"  generator = create_generator('distilgpt2')\")\n",
        "print(f\"  model_path = generator.train_model()\")\n",
        "print(f\"  generator.load_model(model_path)\")\n",
        "print(f\"  domains = generator.generate_domains('your business idea')\")\n",
        "\n",
        "print(f\"\\nğŸŒŸ Thank you for using the Domain Name Generator!\")\n",
        "print(f\"   For questions or improvements, check the project repository.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9328effbf2494551aed86b8efe53009f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91136012d20b40b48cf58fcead82bace",
              "IPY_MODEL_1a718a0220954fb689749af0f3225f33",
              "IPY_MODEL_689a401a051047b8a5367cff9a71fb74"
            ],
            "layout": "IPY_MODEL_356c747281fb47d5878a78b8a9dd0856"
          }
        },
        "91136012d20b40b48cf58fcead82bace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569c14305ace47438065fca4745fd108",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a3e37f2d829447e6825b690a7edde1a7",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "1a718a0220954fb689749af0f3225f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d1c2568ca941349d46b7ffec5e08ba",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_995d83ed073c46eb83a4abeafbd19a31",
            "value": 26
          }
        },
        "689a401a051047b8a5367cff9a71fb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb84084d0e9641a1bfa001f476151556",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f171d1f6da7240878923a91db5c4c927",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡2.45kB/s]"
          }
        },
        "356c747281fb47d5878a78b8a9dd0856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569c14305ace47438065fca4745fd108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3e37f2d829447e6825b690a7edde1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d1c2568ca941349d46b7ffec5e08ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995d83ed073c46eb83a4abeafbd19a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb84084d0e9641a1bfa001f476151556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f171d1f6da7240878923a91db5c4c927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3bfbc10cb4489da04d160c08944aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42fb24029b1148459080c1c4d1b4667c",
              "IPY_MODEL_0288f5c7e9114fd8b5fa3fa5591b63c1",
              "IPY_MODEL_33ef2c645d7c4f85b669a30285219462"
            ],
            "layout": "IPY_MODEL_de15329451774602be0c06b77c886da0"
          }
        },
        "42fb24029b1148459080c1c4d1b4667c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3b0a8fa01db4eeeb8b487a371c0b609",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41a03e7373374d93a0c94b3e4e59bbf6",
            "value": "config.json:â€‡100%"
          }
        },
        "0288f5c7e9114fd8b5fa3fa5591b63c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98f719267fb4e59945c6ef1291477a6",
            "max": 762,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_998743c7aade46c1867040cf8525d69a",
            "value": 762
          }
        },
        "33ef2c645d7c4f85b669a30285219462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb2672e4b5644a6b28b5936232eb082",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4eb4f9e8b44646b1b524a55642126eff",
            "value": "â€‡762/762â€‡[00:00&lt;00:00,â€‡70.6kB/s]"
          }
        },
        "de15329451774602be0c06b77c886da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b0a8fa01db4eeeb8b487a371c0b609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a03e7373374d93a0c94b3e4e59bbf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b98f719267fb4e59945c6ef1291477a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998743c7aade46c1867040cf8525d69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bb2672e4b5644a6b28b5936232eb082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb4f9e8b44646b1b524a55642126eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24bdbf5001fc4396a3477dbf2e6dc1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b53912b45534b7cb0cbf6e4746e2615",
              "IPY_MODEL_74cb3054c7bb49d0aefd3e2d85a2ca53",
              "IPY_MODEL_31449ddacd2b45348fe4909120b860f4"
            ],
            "layout": "IPY_MODEL_c423cef1028b4a4c91a039b3bb442686"
          }
        },
        "0b53912b45534b7cb0cbf6e4746e2615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c03a16be6649c2ae0b83fa8ff5ee21",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8a9e47c7437d42c98e5769de5a39990b",
            "value": "vocab.json:â€‡100%"
          }
        },
        "74cb3054c7bb49d0aefd3e2d85a2ca53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8f82024a704d28bfca3a477ab5cffd",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca33f79ee75c4c498dc34dc495d60084",
            "value": 1042301
          }
        },
        "31449ddacd2b45348fe4909120b860f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b5e38e954e4e1ba035ccc39217fb75",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c3471e5390cf4dedad5f727ffe34a394",
            "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡5.44MB/s]"
          }
        },
        "c423cef1028b4a4c91a039b3bb442686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c03a16be6649c2ae0b83fa8ff5ee21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a9e47c7437d42c98e5769de5a39990b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae8f82024a704d28bfca3a477ab5cffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca33f79ee75c4c498dc34dc495d60084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2b5e38e954e4e1ba035ccc39217fb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3471e5390cf4dedad5f727ffe34a394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7646620eb2574b0e8ed6fba8768bf89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80404245b0bb49fcb72ca4f85387bc7e",
              "IPY_MODEL_4d6c0f533765473cb5003702298a4bc4",
              "IPY_MODEL_6be5e4d3f79e4614b301eb4d6b4db3c1"
            ],
            "layout": "IPY_MODEL_61988e5bd4a34d3db71e36ef5ba00c80"
          }
        },
        "80404245b0bb49fcb72ca4f85387bc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a813a2e321748d19ddfc2de1f34d44c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_be4eb86220e044f9a3e5ac902c1aed66",
            "value": "merges.txt:â€‡100%"
          }
        },
        "4d6c0f533765473cb5003702298a4bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a69c5321a0a49359fa45693a8f2cbae",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_688f07cfa5d34b3fb16486c37d89def1",
            "value": 456318
          }
        },
        "6be5e4d3f79e4614b301eb4d6b4db3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e5767343fd4adabca2efdd3d3b4aef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ff6381930bc417e948eef3747d8ea19",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡6.96MB/s]"
          }
        },
        "61988e5bd4a34d3db71e36ef5ba00c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a813a2e321748d19ddfc2de1f34d44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4eb86220e044f9a3e5ac902c1aed66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a69c5321a0a49359fa45693a8f2cbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688f07cfa5d34b3fb16486c37d89def1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4e5767343fd4adabca2efdd3d3b4aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff6381930bc417e948eef3747d8ea19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e9840dc4ef4468a60c1d405c9ee2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9dd3b1d56b84f0b89e41a0dbed22308",
              "IPY_MODEL_bfe4484b2fcc43f2a4953565ec586e13",
              "IPY_MODEL_66d9267d59ff4df188dd3f58f291c148"
            ],
            "layout": "IPY_MODEL_6ab932c2f7d44a8495c4a96d1af1cbb5"
          }
        },
        "c9dd3b1d56b84f0b89e41a0dbed22308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7435af55dce640d2be25067a2e91a00a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f666a0a861dd4542a9c25c89d9adc3ad",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "bfe4484b2fcc43f2a4953565ec586e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a5f7a7f7644f45b081a72bc80a90e4",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f53ee284aca448288dda9c25bd69cd1",
            "value": 1355256
          }
        },
        "66d9267d59ff4df188dd3f58f291c148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ade627379b914b22926ae792d3c32a09",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ea74fa0731c4cd69bdc19f5a5fed73f",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡6.88MB/s]"
          }
        },
        "6ab932c2f7d44a8495c4a96d1af1cbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7435af55dce640d2be25067a2e91a00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f666a0a861dd4542a9c25c89d9adc3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9a5f7a7f7644f45b081a72bc80a90e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f53ee284aca448288dda9c25bd69cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ade627379b914b22926ae792d3c32a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea74fa0731c4cd69bdc19f5a5fed73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35bee5692f28415589540a2b54c50ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfd009e8e2504c5db03c86d271b1b75c",
              "IPY_MODEL_1269e547372e4f23831e46ce4fa1299e",
              "IPY_MODEL_73840f7eaff64d81ab93d979ee7dd1c6"
            ],
            "layout": "IPY_MODEL_ae07bf82ade7455ab1db9b0d852259d3"
          }
        },
        "cfd009e8e2504c5db03c86d271b1b75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3e4a78bd5a46dab208e4c17c4dcddc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5cfd4045103a46319269224f064ae749",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "1269e547372e4f23831e46ce4fa1299e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4c403bf5ca426686764e5fa3a3f11c",
            "max": 352824413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_982eccda1da44db9838c7b4bd5865ad2",
            "value": 352824413
          }
        },
        "73840f7eaff64d81ab93d979ee7dd1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5452a66bc60a4f70a40c3ae2b46a6f06",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f1aa32402554ebfb92d3680936203bb",
            "value": "â€‡353M/353Mâ€‡[00:06&lt;00:00,â€‡78.9MB/s]"
          }
        },
        "ae07bf82ade7455ab1db9b0d852259d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3e4a78bd5a46dab208e4c17c4dcddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfd4045103a46319269224f064ae749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b4c403bf5ca426686764e5fa3a3f11c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982eccda1da44db9838c7b4bd5865ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5452a66bc60a4f70a40c3ae2b46a6f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1aa32402554ebfb92d3680936203bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2efc7cb180f54ca3a67908b6d65c092a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_968c7751138d45b2bd10718ba8718595",
              "IPY_MODEL_62ab47d99076450badb5ccb8207e5a55",
              "IPY_MODEL_3b890aa9ee5140e3b7437f4e19e630e8"
            ],
            "layout": "IPY_MODEL_2d8eb25cd5774755946bf6cd0190f0ae"
          }
        },
        "968c7751138d45b2bd10718ba8718595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fc0ba8ce5c40a5a6b389932f9fa994",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_788015dfa7f74bd788df055ceab79139",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "62ab47d99076450badb5ccb8207e5a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f4a953f82324c828f4de98dcc65a038",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2edf272357044b4883ca8476fd0f5f83",
            "value": 124
          }
        },
        "3b890aa9ee5140e3b7437f4e19e630e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8255074ac8f240549a6ef636b505eff1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41eb2ef19f5e4a6bb8a24b4d94427859",
            "value": "â€‡124/124â€‡[00:00&lt;00:00,â€‡14.4kB/s]"
          }
        },
        "2d8eb25cd5774755946bf6cd0190f0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39fc0ba8ce5c40a5a6b389932f9fa994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788015dfa7f74bd788df055ceab79139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4a953f82324c828f4de98dcc65a038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edf272357044b4883ca8476fd0f5f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8255074ac8f240549a6ef636b505eff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41eb2ef19f5e4a6bb8a24b4d94427859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "636615a8120640db9951428d3a7932bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45be3ed3054648f8866ec9e9f4336223",
              "IPY_MODEL_334c250e58464f23aa77c828c9cbb4aa",
              "IPY_MODEL_4b5ab42884634828a7e80e8c103d6626"
            ],
            "layout": "IPY_MODEL_54bb7bcd62f843638807b29d679c557f"
          }
        },
        "45be3ed3054648f8866ec9e9f4336223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1da590a07b42a7a5e748f049f954db",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ead32ed8872241b48294a36185674dcd",
            "value": "Map:â€‡100%"
          }
        },
        "334c250e58464f23aa77c828c9cbb4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abc4a43ff07b4f7094eba7a7d22b9565",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50318cea4a514198808921dbeeb33b11",
            "value": 20
          }
        },
        "4b5ab42884634828a7e80e8c103d6626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ecb40c621c4a40b62fac74e6cc379a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_838094ccef244d7fb5c1b38c78a9736d",
            "value": "â€‡20/20â€‡[00:00&lt;00:00,â€‡277.22â€‡examples/s]"
          }
        },
        "54bb7bcd62f843638807b29d679c557f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1da590a07b42a7a5e748f049f954db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead32ed8872241b48294a36185674dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abc4a43ff07b4f7094eba7a7d22b9565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50318cea4a514198808921dbeeb33b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2ecb40c621c4a40b62fac74e6cc379a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838094ccef244d7fb5c1b38c78a9736d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}